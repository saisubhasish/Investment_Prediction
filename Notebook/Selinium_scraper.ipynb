{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a3006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_6392\\1648956513.py:29: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(cd_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "save_file_to_path = \"D:/FSDS-iNeuron/10.Projects-DS/Investment_Prediction_DataPipeline/sample_data/kafka-investment-prediction-topic/\"\n",
    "\n",
    "class data_scraper:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def scraper(self, company, start_date, end_date, cd_path):\n",
    "\n",
    "        # Step 1: Create a session and load the page\n",
    "        #start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        #end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        '''\n",
    "        To automate the process of changing start date and end date in the code, \n",
    "        We can create a function that takes start date and end date as input parameters and formats them as Unix timestamps. \n",
    "        We can then construct the URL with the formatted timestamps as query parameters.\n",
    "        '''\n",
    "        start_timestamp = int(time.mktime(time.strptime(start_date, '%Y-%m-%d')))\n",
    "        end_timestamp = int(time.mktime(time.strptime(end_date, '%Y-%m-%d')))\n",
    "\n",
    "        url = f'https://in.investing.com/equities/{company}-historical-data?end_date={end_timestamp}&st_date={start_timestamp}'\n",
    "        \n",
    "        driver = webdriver.Chrome(cd_path)\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "        \n",
    "        \n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(2) \n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,500)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,-2000)\",\"\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Step 2: Close the pop-up if it appears\n",
    "\n",
    "        try:\n",
    "            maybe_later_button = driver.find_element_by_xpath(\"//button[contains(text(),'Maybe later')]\")\n",
    "            maybe_later_button.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Step 3: Parse HTML code and grab tables with Beautiful Soup\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        tables = soup.find_all('table')\n",
    "\n",
    "        # Step 4: Read tables with Pandas read_html()\n",
    "        dfs = pd.read_html(str(tables))\n",
    "\n",
    "        print(f'Total tables: {len(dfs)}')\n",
    "        print(dfs[0])\n",
    "\n",
    "        driver.close()\n",
    "        dfs[0].to_csv(f'{save_file_to_path}{company}.csv')\n",
    "\n",
    "# example usage\n",
    "scraper = data_scraper()\n",
    "scraper.scraper('tata-consultancy-services', '2016-03-19', '2023-03-19', r\"D:\\FSDS-iNeuron\\10.Projects-DS\\Investment_Prediction\\Selenium\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "#britannia-industries --> Britannia Inductries\n",
    "#itc --> ITC\n",
    "#reliance-industries --> Reliance Industries\n",
    "#tata-consultancy-services  -->  TCS\n",
    "#tata-motors-ltd --> TATA Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfb200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
